import datetime
import json
import logging
import os
from typing import Any, Dict, List, Optional, Union

import aiofiles
import aiohttp
import httpx
from dotenv import load_dotenv
from gpt_utils import extract_json_from_gpt_response
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from openai import AsyncOpenAI
from redis_setting import load_from_redis, save_to_redis

logger = logging.getLogger(__name__)

# ìµœìƒìœ„ ë””ë ‰í† ë¦¬ì˜ .env íŒŒì¼ ë¡œë“œ
load_dotenv(os.path.join(os.path.dirname(os.path.dirname(__file__)), '.env'))

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
openai_client = AsyncOpenAI(api_key=OPENAI_API_KEY)


async def create_feature_definition(email: str, description: str, definition_url: Optional[str] = None) -> Dict[str, Any]:
    """
    ê¸°ëŠ¥ ì •ì˜ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        email (str): ì‚¬ìš©ì ì´ë©”ì¼
        description (str): ê¸°ëŠ¥ ì •ì˜ì„œ í…ìŠ¤íŠ¸
        definition_url (Optional[str]): ê¸°ëŠ¥ ì •ì˜ì„œ URL
        
    Returns:
        Dict[str, Any]: ê¸°ëŠ¥ ì •ì˜ì„œ ë°ì´í„°
    """
    
    # user_inputì€ ê¸°ëŠ¥ ë° ì„œë¹„ìŠ¤ì— ëŒ€í•œ descriptionìœ¼ë¡œì„œ ì‚¬ì „ ì •ì˜ëœ ê¸°ëŠ¥ ì •ì˜ì„œ ì—¬ë¶€ì™€ ê´€ê³„ì—†ì´ ì‚¬ìš©ë¨.
    email = email
    user_input = description
    predefined_definition = definition_url
    
    # ì‚¬ì „ ì •ì˜ëœ ê¸°ëŠ¥ ì •ì˜ì„œ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    if predefined_definition:
        logger.info("ê¸°ëŠ¥ ì •ì˜ì„œê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.")
        try:
            asset_dir=os.path.join(os.path.dirname(os.path.dirname(__file__)), "asset")
            os.makedirs(asset_dir, exist_ok=True)
            
            filename=os.path.basename(predefined_definition)
            file_path=os.path.join(asset_dir, filename)
        
            async with aiohttp.ClientSession() as session:
                async with session.get(predefined_definition) as response:
                    if response.status == 200:
                        async with aiofiles.open(file_path, mode="wb") as f:
                            await f.write(await response.content.read())
                        
                        async with aiofiles.open(file_path, 'r', encoding='utf-8') as f:
                            definition_content = await f.read()
                            #logger.info(f"ì •ì˜ì„œ ë‚´ìš©: {definition_content}")
                    else:
                        logger.error(f"ê¸°ëŠ¥ ì •ì˜ì„œ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {response.status}", exc_info=True)
        except Exception as e:
            logger.error(f"ê¸°ëŠ¥ ì •ì˜ì„œ ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
            raise Exception(f"ê¸°ëŠ¥ ì •ì˜ì„œ ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True) from e
        
        # GPT API í˜¸ì¶œì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ì •ì˜
        create_feature_prompt = ChatPromptTemplate.from_template("""
        ë‹¹ì‹ ì€ ì†Œí”„íŠ¸ì›¨ì–´ ìš”êµ¬ì‚¬í•­ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì£¼ë‹ˆì–´ ê°œë°œíŒ€ì˜ ì…ì¥ì—ì„œ ê°œë°œí•˜ë ¤ëŠ” ì„œë¹„ìŠ¤ì— í•„ìš”í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ëŠ” ê¸°ëŠ¥ ëª©ë¡ì„ ì •ì˜í•˜ëŠ” ê²ƒì´ ë‹¹ì‹ ì˜ ì„ë¬´ì…ë‹ˆë‹¤. 
        ê° ê¸°ëŠ¥ì€ êµ¬í˜„ ê°€ëŠ¥í•œ ì‘ì€ ë‹¨ìœ„ì—¬ì•¼ í•˜ê³ , ë°˜ë“œì‹œ ì¤‘ë³µë˜ì§€ ì•Šì•„ì•¼ í•©ë‹ˆë‹¤.

        ë‹¤ìŒì€ ê°œë°œíŒ€ì´ ì‚¬ì „ì— ì •ì˜í•œ ì •ì˜ì„œì˜ ë‚´ìš©ì…ë‹ˆë‹¤:
        {definition_content}

        ìœ„ ì •ì˜ì„œë¥¼ ìì„¸íˆ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì‚¬í•­ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”:
        1. ì •ì˜ì„œì— ëª…ì‹œëœ ëª¨ë“  ê¸°ëŠ¥ì„ ì¶”ì¶œí•˜ì—¬ features ë°°ì—´ì— í¬í•¨ì‹œì¼œì£¼ì„¸ìš”.
        2. ì •ì˜ì„œì— ëª…ì‹œëœ ê¸°ëŠ¥ ì™¸ì— ì¶”ê°€ë¡œ í•„ìš”í•œ ê¸°ëŠ¥ì„ ì œì•ˆí•´ì£¼ì„¸ìš”.

        ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
        {{
            "features": [
                "ì •ì˜ì„œì—ì„œ ì¶”ì¶œí•œ ê¸°ëŠ¥1",
                "ì •ì˜ì„œì—ì„œ ì¶”ì¶œí•œ ê¸°ëŠ¥2",
                ...
            ],
            "suggestions": [
                {{
                    "question": "ì´ëŸ° ê¸°ëŠ¥ì„ ì¶”ê°€í•˜ì‹œëŠ” ê±´ ì–´ë–¤ê°€ìš”?",
                    "answers": [
                        "ì¶”ê°€ ì œì•ˆ ê¸°ëŠ¥1",
                        "ì¶”ê°€ ì œì•ˆ ê¸°ëŠ¥2",
                        ...
                    ]
                }}
            ]
        }}

        ì£¼ì˜ì‚¬í•­:
        1. ì •ì˜ì„œì— ëª…ì‹œëœ ëª¨ë“  ê¸°ëŠ¥ì„ ë°˜ë“œì‹œ í¬í•¨í•´ì£¼ì„¸ìš”.
        2. ê° ê¸°ëŠ¥ì€ ì´ë¦„ë§Œ ì‘ì„±í•˜ë©° ëª¨ë‘ "~ê¸°ëŠ¥"ìœ¼ë¡œ ëë‚˜ì•¼ í•©ë‹ˆë‹¤.
        3. ê¸°ëŠ¥ ê°„ ì¤‘ë³µì´ ì—†ë„ë¡ í•´ì£¼ì„¸ìš”.

        í”„ë¡œì íŠ¸ ì„¤ëª…:
        {user_input}
        """)
        
        # GPT API í˜¸ì¶œ
        message = create_feature_prompt.format_messages(
            definition_content=definition_content,
            user_input=user_input
        )
        llm = ChatOpenAI(model="gpt-4o", temperature=0.7)
        response = llm.invoke(message)
        
        # ì‘ë‹µ íŒŒì‹±
        content = response.content
        try:
            gpt_result = extract_json_from_gpt_response(content)
        except Exception as e:
            logger.error(f"GPT util ì‚¬ìš© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
            raise Exception(f"GPT util ì‚¬ìš© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True) from e
        
        # features, suggestions ì¶”ì¶œ
        features = gpt_result["features"]
        suggestions = gpt_result["suggestions"][0]["answers"]
        print("ê¸°ëŠ¥ ì •ì˜ì„œë¡œë¶€í„° ì¶”ì¶œí•œ ê¸°ëŠ¥ ëª©ë¡: ", features)
        print("ê¸°ëŠ¥ ì •ì˜ì„œë¡œë¶€í„° ì¶”ì¶œí•œ ì œì•ˆ ëª©ë¡: ", suggestions)
        
    else:
        print("ê¸°ëŠ¥ ì •ì˜ì„œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        logger.info("ê¸°ëŠ¥ ì •ì˜ì„œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        
        # GPT API í˜¸ì¶œì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ì •ì˜
        create_feature_prompt = ChatPromptTemplate.from_template("""
        ë‹¹ì‹ ì˜ ì—­í• ì€ ì£¼ë‹ˆì–´ ê°œë°œíŒ€ì˜ ì…ì¥ì—ì„œ ê°œë°œí•˜ë ¤ëŠ” ì„œë¹„ìŠ¤ì— í•„ìš”í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ëŠ” ê¸°ëŠ¥ ëª©ë¡ì„ ì •ì˜í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. 
        ê° ê¸°ëŠ¥ì€ êµ¬í˜„ ê°€ëŠ¥í•œ ì‘ì€ ë‹¨ìœ„ì—¬ì•¼ í•˜ê³ , ë°˜ë“œì‹œ ì¤‘ë³µë˜ì§€ ì•Šì•„ì•¼ í•©ë‹ˆë‹¤.
        ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì¶”ê°€í•˜ë©´ ì¢‹ì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ëŠ” ê¸°ëŠ¥ ëª©ë¡ì„ ì œì•ˆí•´ ì£¼ì„¸ìš”:
        {{
            "suggestions": [
                {{
                    "question": "ì´ëŸ° ê¸°ëŠ¥ì„ ì¶”ê°€í•˜ì‹œëŠ” ê±´ ì–´ë–¤ê°€ìš”?",
                    "answers": ["ê²°ì œ ê¸°ëŠ¥", "ì£¼ë¬¸ ê¸°ëŠ¥", "ì£¼ë¬¸ ì¡°íšŒ ê¸°ëŠ¥"]
                }}
            ]
        }}
        
        í”„ë¡œì íŠ¸ ì„¤ëª…:
        {user_input}
        """)
        
        # GPT API í˜¸ì¶œ
        message = create_feature_prompt.format_messages(user_input=user_input)
        llm = ChatOpenAI(model="gpt-4o", temperature=0.7)
        response = llm.invoke(message)
        
        # ì‘ë‹µ íŒŒì‹±
        content = response.content
        try:
            gpt_result = extract_json_from_gpt_response(content)
        except Exception as e:
            logger.error(f"GPT util ì‚¬ìš© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
            raise Exception(f"GPT util ì‚¬ìš© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True) from e

        # suggestions ì¶”ì¶œ
        features = []
        suggestions = gpt_result["suggestions"][0]["answers"]
        print("ê¸°ëŠ¥ ì •ì˜ì„œë¡œë¶€í„° ì¶”ì¶œí•œ ì œì•ˆ ëª©ë¡: ", suggestions)
        
    # íŒŒì‹±ëœ ê²°ê³¼ ë°˜í™˜
    result = {
        "suggestion": {
            "features": features,
            "suggestions": [
                {
                    "question": "ì´ëŸ° ê¸°ëŠ¥ì„ ì¶”ê°€í•˜ì‹œëŠ” ê±´ ì–´ë–¤ê°€ìš”?",
                    "answers": suggestions
                }
            ]
        }
    }
    logger.info(f"ğŸ‘‰ API ì‘ë‹µ ê²°ê³¼: {result}")
    
    # Redisì— ì €ì¥í•  ë°ì´í„° êµ¬ì„± (featuresì™€ suggestionsì˜ answersë§Œ í¬í•¨)
    all_features = features + suggestions
        
    # Redisì— ì €ì¥
    await save_to_redis(f"features:{email}", all_features)
    logger.info(f"Redisì— ë°ì´í„° ì €ì¥ ì™„ë£Œ: {all_features}")
    
    return result

async def update_feature_definition(email: str, feedback: str) -> Dict[str, Any]:
    """
    ì‚¬ìš©ì í”¼ë“œë°±ì„ ê¸°ë°˜ìœ¼ë¡œ ê¸°ëŠ¥ ì •ì˜ì„œë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    
    Args:
        email (str): ì‚¬ìš©ì ì´ë©”ì¼
        feedback (str): ì‚¬ìš©ì í”¼ë“œë°±
        
    Returns:
        Dict[str, Any]: ì—…ë°ì´íŠ¸ëœ ê¸°ëŠ¥ ì •ì˜ì„œ ë°ì´í„°
            - features: ì—…ë°ì´íŠ¸ëœ ê¸°ëŠ¥ ëª©ë¡
            - isNextStep: ë‹¤ìŒ ë‹¨ê³„ ì§„í–‰ ì—¬ë¶€ (1: ì¢…ë£Œ, 0: ê³„ì†)
    """
    email = email
    feedback = feedback
    
    try:
        feature_data = await load_from_redis(f"features:{email}")
    except Exception as e:
        logger.error(f"Redisì—ì„œ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
        raise Exception(f"Redisì—ì„œ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True) from e
    
    if not feature_data:
        raise ValueError(f"Project information for user {email} not found")
    
    print(f"type of feature_data: ", type(feature_data))
    # Redisì—ì„œ ê°€ì ¸ì˜¨ ë°ì´í„°ê°€ ë¬¸ìì—´ì¸ ê²½ìš°ì—ë§Œ JSON íŒŒì‹±
    if isinstance(feature_data, str):
        feature_data = json.loads(feature_data)
    
    # 1. í”¼ë“œë°± ë¶„ì„
    update_prompt = ChatPromptTemplate.from_template("""
    ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ í”¼ë“œë°±ì„ ë¶„ì„í•˜ì—¬ ê¸°ëŠ¥ ì •ì˜ ë‹¨ê³„ë¥¼ ê³„ì† ì§„í–‰í• ì§€ ì¢…ë£Œí• ì§€ íŒë‹¨í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

    ë‹¤ìŒì€ ê¸°ëŠ¥ ì •ì˜ ë‹¨ê³„ì—ì„œ ë°›ì€ ì‚¬ìš©ìì˜ í”¼ë“œë°±ì…ë‹ˆë‹¤:
    {feedback}

    ì´ í”¼ë“œë°±ì´ ë‹¤ìŒ ì¤‘ ì–´ë–¤ ìœ í˜•ì¸ì§€ íŒë‹¨í•´ì£¼ì„¸ìš”:
    1. ìˆ˜ì •/ì¶”ê°€ ìš”ì²­:
    - ìƒˆë¡œìš´ ê¸°ëŠ¥ ì¶”ê°€ ìš”ì²­
    - ê¸°ì¡´ ê¸°ëŠ¥ ìˆ˜ì • ìš”ì²­
    - ê¸°ëŠ¥ ëª©ë¡ ë³€ê²½ ìš”ì²­
    ì˜ˆì‹œ: "ì¥ë°”êµ¬ë‹ˆ ê¸°ëŠ¥ ì¶”ê°€í•´ì£¼ì„¸ìš”", "ê²°ì œ ê¸°ëŠ¥ë„ í•„ìš”í•´ìš”"

    2. ì¢…ë£Œ ìš”ì²­:
    - ê¸°ëŠ¥ ì •ì˜ ì™„ë£Œ ì˜ì‚¬ í‘œí˜„
    - ë” ì´ìƒì˜ ìˆ˜ì •ì´ í•„ìš” ì—†ë‹¤ëŠ” ì˜ê²¬
    - ë‹¤ìŒ ë‹¨ê³„ë¡œ ë„˜ì–´ê°€ê³  ì‹¶ë‹¤ëŠ” ì˜ê²¬
    ì˜ˆì‹œ: "ì´ëŒ€ë¡œ ì¢‹ìŠµë‹ˆë‹¤", "ë” ì´ìƒ ìˆ˜ì •í•  í•„ìš” ì—†ì–´ìš”", "ë‹¤ìŒìœ¼ë¡œ ë„˜ì–´ê°€ì£ "

    1ë²ˆ ìœ í˜•ì˜ ê²½ìš°ëŠ” isNextStepì„ 0ìœ¼ë¡œ, 2ë²ˆ ìœ í˜•ì˜ ê²½ìš°ëŠ” isNextStepì„ 1ë¡œ ì„¤ì •í•´ì£¼ì„¸ìš”.
    ì‘ë‹µì€ ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:
    {{
        "isNextStep": 1
    }}
    """)
    
    message = update_prompt.format_messages(feedback=feedback)
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.7)
    response = llm.invoke(message)
    
    try:
        content = response.content
        gpt_result = extract_json_from_gpt_response(content)
    except Exception as e:
        logger.error(f"GPT util ì‚¬ìš© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
        raise Exception(f"GPT util ì‚¬ìš© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True) from e
    
    is_next_step = gpt_result["isNextStep"]
    
    if is_next_step == 1:
        result = {
            "features": feature_data,
            "isNextStep": 1
        }
        logger.info(f"ğŸ‘‰ API ì‘ë‹µ ê²°ê³¼: {result}")
        return result
    
    
    if is_next_step == 0:
        # 2. ê¸°ëŠ¥ì„ ìˆ˜ì •/ì¶”ê°€/ì‚­ì œí•  ê²ƒì„ ìš”ì²­í•˜ëŠ” ì‚¬ìš©ì í”¼ë“œë°±ì´ë¯€ë¡œ, ê¸°ëŠ¥ ëª©ë¡ì„ ì—…ë°ì´íŠ¸ í•©ë‹ˆë‹¤.
        update_features_prompt = ChatPromptTemplate.from_template("""
        í˜„ì¬ ê¸°ëŠ¥ ì •ì˜ì„œì™€ ì‚¬ìš©ì í”¼ë“œë°±ì„ ê¸°ë°˜ìœ¼ë¡œ ê¸°ëŠ¥ì„ ì—…ë°ì´íŠ¸í•´ì£¼ì„¸ìš”.

        í˜„ì¬ ê¸°ëŠ¥ ëª©ë¡:
        {current_features}

        ì‚¬ìš©ì í”¼ë“œë°±:
        {feedback}

        ì‘ë‹µì€ ë°˜ë“œì‹œ ë‹¤ìŒê³¼ ê°™ì€ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ì„±í•´ì£¼ì„¸ìš”:
        {{
            "features": [
                "ê¸°ëŠ¥ëª…1",
                "ê¸°ëŠ¥ëª…2",
                "ê¸°ëŠ¥ëª…3"
            ]
        }}

        ì¶”ê°€ ì„¤ëª…ì´ë‚˜ ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
        """)
    
        message = update_features_prompt.format_messages(
            current_features=feature_data,
            feedback=feedback
        )
        llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.7)
        response = llm.invoke(message)
    
        # ì‘ë‹µ íŒŒì‹±
        try:
            content = response.content

            try:
                updated_features = extract_json_from_gpt_response(content)
            except Exception as e:
                logger.error(f"GPT util ì‚¬ìš© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
                raise Exception(f"GPT util ì‚¬ìš© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True) from e
        
            if not isinstance(updated_features, dict) or "features" not in updated_features:
                raise ValueError("ì‘ë‹µì´ ì˜¬ë°”ë¥¸ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤. 'features' í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            if not isinstance(updated_features["features"], list):
                raise ValueError("'features'ëŠ” ë¦¬ìŠ¤íŠ¸ í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
            
        except Exception as e:
            logger.error(f"GPT API ì‘ë‹µ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
            raise Exception(f"GPT API ì‘ë‹µ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True) from e
        
        # Redis ì—…ë°ì´íŠ¸
        # ì—…ë°ì´íŠ¸ ì „ ë°ì´í„° ë¡œê¹…
        print(f"ì—…ë°ì´íŠ¸ ì „ Redis ë°ì´í„°: {feature_data}")
        logger.info(f"ì—…ë°ì´íŠ¸ ì „ Redis ë°ì´í„°: {feature_data}")
    
        # ê¸°ëŠ¥ ëª©ë¡ ì—…ë°ì´íŠ¸
        feature_data = updated_features["features"]
    
        # ì—…ë°ì´íŠ¸í•  ë°ì´í„° ë¡œê¹…
        print(f"ì—…ë°ì´íŠ¸ í›„ Redis ë°ì´í„°: {feature_data}, \në‹¤ìŒê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”: {updated_features['features']}")
        logger.info(f"ì—…ë°ì´íŠ¸ í›„ Redis ë°ì´í„°: {feature_data}")
    
        # Redisì— ì €ì¥
        await save_to_redis(f"features:{email}", feature_data)
    
        # API ì‘ë‹µìš© ê²°ê³¼ ë°˜í™˜
        result = {
            "features": feature_data,
            "isNextStep": 0
        }
        logger.info(f"ğŸ‘‰ API ì‘ë‹µ ê²°ê³¼: {result}")
        return result
