import logging
import os
from collections import defaultdict
from typing import List

import torch
from dotenv import load_dotenv
from gpt_utils import extract_json_from_gpt_response
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from mongodb_setting import (get_epic_collection, get_project_collection,
                             get_user_collection)
from openai import AsyncOpenAI
from project_member_utils import get_project_members
from transformers import AutoModelForTokenClassification, AutoTokenizer

logger = logging.getLogger(__name__)

load_dotenv(os.path.join(os.path.dirname(os.path.dirname(__file__)), '.env'))
#os.environ["TOKENIZERS_PARALLELISM"] = "false"

#HUGGINGFACE_API_KEY = os.getenv("HUGGINGFACE_API_KEY")
#login(token=HUGGINGFACE_API_KEY)


'''
Tokenì€ BIO í˜•ì‹ ê¸°ë°˜ìœ¼ë¡œ ì²˜ë¦¬. BIO í˜•ì‹ì€ ê° í† í°ì— ëŒ€í•´ íƒœê·¸ ë¶€ì—¬ ë°©ì‹ì„ ì •ì˜í•œ ê²ƒ.

B: Begin, I: Inside, O: Outside
B-PER: ì‹œì‘ í† í°, I-PER: ì¤‘ê°„ í† í°, O: ê·¸ ì™¸ í† í°
'''


original_model_name = "monologg/koelectra-base-v3-naver-ner"
'''
ìŠ¤í™ ì§§ê²Œ ì •ë¦¬: 
    - koelectra-base-v3 (í•œêµ­ì–´ ELECTRA ë³€í˜•)ì´ ê¸°ë°˜ ëª¨ë¸
    - Input: 512 tokens
    - Class: 41ê°œ NER tagì— ëŒ€í•´ í•™ìŠµí•¨
    - tokenizer íŠ¹ì§•: ê³µë°±, ë‹¨ì–´ ê²½ê³„ ë¬´ì‹œ && Sentence ë‹¨ìœ„ë¡œ ë¶„ë¦¬í•¨
    - F1-SCORE: 92.4
    - # of parameters: 110M
    - ì†ë„: ë¹ ë¦„
'''

tokenizer = AutoTokenizer.from_pretrained(original_model_name)
model_for_ner = AutoModelForTokenClassification.from_pretrained(original_model_name)

### ==================== íšŒì˜ ì•¡ì…˜ ì•„ì´í…œ ìƒì„± - íŒŒì¸íŠœë‹ ëª¨ë¸ ì‚¬ìš© ==================== ###
async def create_action_items_finetuned(content: str):
    logger.info(f"ğŸ” íšŒì˜ ì•¡ì…˜ ì•„ì´í…œ ìƒì„± ì‹œì‘")
    
    # ëª¨ë¸ì˜ ì…ë ¥ token ë‹¨ìœ„ê°€ 512ê°œì´ë¯€ë¡œ, ì´ë¥¼ ë§ì¶”ê¸° ìœ„í•´ ë¬¸ë‹¨ ë‹¨ìœ„ë¡œ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
    paragraphs = content.split("\n\n")
    entities = []
    
    # ê° ë¬¸ë‹¨ë³„ë¡œ ì²˜ë¦¬
    for paragraph in paragraphs:
        if not paragraph.strip():   # ë¹„ì–´ ìˆëŠ” ë¬¸ë‹¨ì€ ìƒëµ
            continue
        
        # ë¬¸ë‹¨ì„ í† í°í™”
        inputs = tokenizer(
            paragraph,
            return_tensors="pt",
            truncation=True,
            max_length=512,  # ëª¨ë¸ì˜ ì…ë ¥ token ë‹¨ìœ„ê°€ 512ê°œì´ë¯€ë¡œ, ì´ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ë§ì¶°ì„œ ì²˜ë¦¬
            return_offsets_mapping=True,
            return_token_type_ids=False,
        )
        offset_mapping = inputs.pop("offset_mapping")[0] # offset mappingì„ í•´ì•¼ ì´í›„ì— í† í°ì— ëŒ€ì‘ë˜ëŠ” ë¬¸ìì—´ì„ ë³µì›í•  ìˆ˜ ìˆìŒ
        
        with torch.no_grad():
            outputs = model_for_ner(**inputs)
        
        logits = outputs.logits
        predictions = torch.argmax(logits, dim=2)[0].tolist()   # listë¡œ ë¬¶ì–´ì„œ ì°¨ì› ì¶•ì†Œ
        input_ids = inputs["input_ids"][0]
        id2label = model_for_ner.config.id2label
        tokens = tokenizer.convert_ids_to_tokens(input_ids)

        current_entity = {"type": None, "text": "", "start": None}
    
        for i, pred in enumerate(predictions):
            label = id2label[pred]
            start, end = offset_mapping[i].tolist()
            text_span = paragraph[start:end]
        
            if "-" in label:
                entity_type, tag = label.split("-")
            else:
                entity_type, tag = label, "0"
                
            if tag == "B":
                # ì´ì „ entity ì €ì¥
                if current_entity["text"]:
                    entities.append(current_entity.copy())
                current_entity = {
                    "type": entity_type,
                    "text": text_span,
                    "start": start,
                }
            elif tag == "I" and current_entity["type"] == entity_type:
                current_entity["text"] += text_span
            else:
                # Outside íƒœê·¸ / type ë¶ˆì¼ì¹˜
                if current_entity["text"]:
                    entities.append(current_entity.copy())
                    current_entity = {"type": None, "text": "", "start": None}
                    
        if current_entity["text"]:
            # ë§ˆì§€ë§‰ entity ì²˜ë¦¬
            entities.append(current_entity.copy())
    
    # ë””ë²„ê¹…ìš© ì¶œë ¥
    print("=== Extracted Entities ===")
    for ent in entities:
        print(ent)
        
    # taskë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ assignee, enddate mapping
    action_items = []
    tasks = [e for e in entities if e["type"] in {"EVT", "TRM"}]
    assignees = [e for e in entities if e["type"] == "PER"]
    enddates = [e for e in entities if e["type"] == "DAT"]
    
    for task in tasks:
        closest_assignee = min(assignees, key=lambda x: abs(x["start"] - task["start"]), default=None)
        closest_enddate = min(enddates, key=lambda x: abs(x["start"] - task["start"]), default=None)
        
        action_items.append({
            "task": task["text"],
            "assignee": closest_assignee["text"] if closest_assignee else "",
            "enddate": closest_enddate["text"] if closest_enddate else "",
        })
        
    ''' 
    ë‹¤ìŒê³¼ ê°™ì€ í˜•íƒœë¡œ action_itemsê°€ ë°˜í™˜ë˜ë©´ ì„±ê³µ
    [
        {
            "task": "ë³´ê³ ì„œ ì œì¶œ",
            "assignee": "ê¹€ìŠ¹ì—°",
            "enddate": "2024ë…„ 10ì›” 1ì¼"
        },
        {
            "task": "ìë£Œ ì •ë¦¬",
            "assignee": "",
            "enddate": ""
        },
    ]
    '''
    logger.info(f"ìµœì¢… ì²˜ë¦¬ëœ action_items: {action_items}")
    
    return action_items
    
### ============================== API ì •ì˜ ============================== ###
### ================ Summary & Action Items Extraction ================== ###
async def create_summary(title: str, content: str, project_id: str):
    '''
    title: ì‚¬ìš©ìê°€ ì œëª©ìœ¼ë¡œ íšŒì˜ë¡ì„ ëŒ€í‘œí•˜ëŠ” ë‚´ìš©ì„ ì…ë ¥í•œë‹¤ê³  ê°€ì • -> ìš”ì•½ì˜ ì²« ë²ˆì§¸ ë¼ˆëŒ€ë¡œ ì‚¬ìš©
    content: Markdown í˜•íƒœë¡œ ë¬¸ì„œê°€ ì œê³µë¨
    '''
    logger.info(f"ğŸ” íšŒì˜ ìš”ì•½ ìƒì„± ì‹œì‘")
    meeting_summary_prompt = ChatPromptTemplate.from_template("""
    ë‹¹ì‹ ì€ íšŒì˜ë¡ì—ì„œ ì¤‘ìš”í•œ ëŒ€í™” ë‚´ìš©ì„ ì •ë¦¬í•´ ì£¼ëŠ” AI ë¹„ì„œì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì£¼ìš” ì–¸ì–´ëŠ” í•œêµ­ì–´ì…ë‹ˆë‹¤. ì •ë¦¬í•œ ë‚´ìš©ì€ Markdown í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ ì£¼ì„¸ìš”.
    ë‹¹ì‹ ì˜ ì—…ë¬´ëŠ” íšŒì˜ ì œëª©ì¸ {title}ì„ ë°”íƒ•ìœ¼ë¡œ íšŒì˜ë¡ {content}ë¥¼ ë¶„ì„í•˜ì—¬ ì¤‘ìš”í•œ ëŒ€í™” ë‚´ìš©ì„ ì •ë¦¬í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
    {title}ì€ íšŒì˜ì˜ ì œëª©ìœ¼ë¡œì„œ íšŒì˜ë¡ì—ì„œ ë…¼ì˜ë˜ëŠ” ë‚´ìš©ì„ ëŒ€í‘œí•˜ëŠ” ê²ƒìœ¼ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤. 
    íšŒì˜ë¡ì˜ ë‚´ìš©ì„ ë¶„ì„í•  ë•Œ {title}ì„ ì ê·¹ì ìœ¼ë¡œ ì°¸ì¡°í•˜ê³ , ìš”ì•½ë³¸ì˜ ë§¨ ì•ì— Heading 1 ë ˆë²¨ë¡œ {title}ì„ ë¶ˆë › í¬ì¸íŠ¸ ì—†ì´ ë„£ìœ¼ì„¸ìš”.
    
    {content}ì— í¬í•¨ëœ tokenì˜ ìˆ˜ê°€ 3000ê°œ ì´ìƒì„ ë„˜ì–´ê°€ë©´ íšŒì˜ ì•ˆê±´, ì•ˆê±´ ë…¼ì˜ ê²°ê³¼, ë‹¤ìŒ íšŒì˜ ì•ˆê±´, ì¤‘ìš” í”¼ë“œë°± ë° ì˜ê²¬ ì •ë¦¬ ë“±ì˜ ëª©ì°¨ë¥¼ êµ¬ì„±í•˜ì—¬ ëª©ì°¨ë³„ë¡œ ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬í•˜ì„¸ìš”.
    3000ê°œ ë¯¸ë§Œì˜ ì§§ì€ íšŒì˜ë¡ì˜ ê²½ìš°ì—ëŠ” ë‚´ìš©ì„ 500ì ì´ë‚´ë¡œ ìµœëŒ€í•œ ì••ì¶•í•´ì„œ ì •ë¦¬í•˜ì„¸ìš”. ì´ ë•Œ ëª©ì°¨ë¥¼ êµ¬ì„±í•˜ì§€ ë§ê³  ë‚´ìš©ì„ ìµœëŒ€í•œ ì••ì¶•í•´ì„œ ì •ë¦¬í•˜ì„¸ìš”.
    
    {content}ì— í¬í•¨ëœ Heading ë ˆë²¨ í‘œì‹œ ë¬¸ìì¸ "#", "**" ë“±ì˜ íŠ¹ìˆ˜ ë¬¸ìëŠ” ìš”ì•½ì„ êµ¬ì„±í•˜ëŠ” ê³¼ì •ì—ë§Œ ì°¸ê³ í•˜ê³  ìš”ì•½ ê²°ê³¼ì—ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
    ìš”ì•½ ê²°ê³¼ëŠ” ë‚´ìš©ì„ ë³´ê¸° ì‰½ê²Œ ë¶ˆë › í¬ì¸íŠ¸ì™€ í•¨ê»˜ ë¬¸ì¥ìœ¼ë¡œ ì •ë¦¬í•˜ì„¸ìš”.
    
    ë°˜ë“œì‹œ ë‹¤ìŒì˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ ì£¼ì„¸ìš”. ë‹¤ë¥¸ í˜•ì‹ì˜ ì‘ë‹µì€ í—ˆìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë§í•˜ì§€ë§Œ ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ ì£¼ì„¸ìš”.
    ë˜í•œ ë°˜ë“œì‹œ summaryë¥¼ Markdown í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”:
    {{
        "summary": "ì—¬ê¸°ì— ìš”ì•½ ë‚´ìš©ì„ Markdown í˜•ì‹ìœ¼ë¡œ ì‘ì„±"
    }}
    """)
    
    project_members = await get_project_members(project_id)
    
    messages = meeting_summary_prompt.format(
        title=title,
        content=content,
        project_members=project_members)
    
    llm = ChatOpenAI(
        model_name="gpt-4o",
        temperature=0.8,
    )
    response = await llm.ainvoke(messages)
    
    try:
        content = response.content
        try:
            gpt_result = extract_json_from_gpt_response(content)
        except Exception as e:
            logger.error(f"GPT util ì‚¬ìš© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
            raise Exception(f"GPT util ì‚¬ìš© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True) from e
        
    except Exception as e:
        logger.error(f"GPT API ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        raise Exception(f"GPT API ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True) from e
    
    summary = gpt_result["summary"]
    logger.info(f"íšŒì˜ ìš”ì•½ ê²°ê³¼: {summary}")
    
    return summary

async def create_action_items_gpt(content: str):
    logger.info(f"ğŸ” íšŒì˜ ì•¡ì…˜ ì•„ì´í…œ ìƒì„± ì‹œì‘")
    action_items_prompt = ChatPromptTemplate.from_template("""
    ë‹¹ì‹ ì€ íšŒì˜ë¡ìœ¼ë¡œë¶€í„° ì•¡ì…˜ ì•„ì´í…œì„ ì¶”ì¶œí•´ì„œ ì •ë¦¬í•˜ëŠ” AI ë¹„ì„œì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì£¼ìš” ì–¸ì–´ëŠ” í•œêµ­ì–´ì…ë‹ˆë‹¤.
    íšŒì˜ë¡ {content}ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì„¸ ê°€ì§€ ìš”ì†Œë¥¼ í¬í•¨í•œ ì•¡ì…˜ ì•„ì´í…œì„ ì¶”ì¶œí•´ ì£¼ì„¸ìš”:
    1. ì•¡ì…˜ ì•„ì´í…œ ë‚´ìš© (description)
    2. ë‹´ë‹¹ì (assignee)
    3. ë§ˆê° ê¸°í•œ (endDate)
    2ë²ˆê³¼ 3ë²ˆì€ íšŒì˜ë¡ì— ì •ë³´ê°€ ì—†ì„ ê²½ìš° nullë¡œ ì§€ì •í•˜ì„¸ìš”.
    ì•¡ì…˜ ì•„ì´í…œì˜ ë‚´ìš©ì€ "~í•˜ê¸°"ë¡œ ëª…ì‚¬í˜• ì–´ë¯¸ë¥¼ ì‚¬ìš©í•´ì„œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ descriptionì„ í•œ ë²ˆ ë” ì •ë¦¬í•˜ëŠ” ê³¼ì •ì„ ê±°ì¹˜ì„¸ìš”.
    
    ê²°ê³¼ë¥¼ ë‹¤ìŒê³¼ ê°™ì€ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ ì£¼ì„¸ìš”. ë‹¤ë¥¸ í˜•ì‹ì˜ ì‘ë‹µì€ í—ˆìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë§í•˜ì§€ë§Œ ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ ì£¼ì„¸ìš”.
    {{
        "actionItems": [
            {{
                "description": "string",
                "assignee": "string" | null,
                "endDate": "string" | null
            }},
            ...
        ]
    }}
    """)
    messages = action_items_prompt.format(content=content)
    llm = ChatOpenAI(
        model_name="gpt-4o",
        temperature=0.5,
    )
    response = await llm.ainvoke(messages)
    try:
        content = response.content
        try:
            gpt_result = extract_json_from_gpt_response(content)
        except Exception as e:
            logger.error(f"GPT util ì‚¬ìš© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
            raise Exception(f"GPT util ì‚¬ìš© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True) from e
    except Exception as e:
        logger.error(f"GPT API ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        raise Exception(f"GPT API ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True) from e
    
    action_items = gpt_result["actionItems"]
    logger.info(f"ìƒì„±ëœ ì•¡ì…˜ ì•„ì´í…œ: {action_items}")
    
    return action_items


async def convert_action_items_to_tasks(action_items: List[str], project_id: str):
    assert action_items is not None, "action_itemsê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    action_items_to_tasks_prompt = ChatPromptTemplate.from_template(
    """
    ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ì•¡ì…˜ ì•„ì´í…œì˜ ì„¸ë¶€ ë‚´ìš©ì„ ì •ë¦¬í•´ì„œ taskë¡œ ë³€í™˜í•˜ëŠ” AI ë¹„ì„œì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì£¼ìš” ì–¸ì–´ëŠ” í•œêµ­ì–´ì…ë‹ˆë‹¤.
    ë‹¹ì‹ ì˜ ì—…ë¬´ëŠ” ì‘ì—… ë‚´ìš©, ì‘ì—… ë‹´ë‹¹ì, ì‘ì—… ë§ˆê°ê¸°í•œ ì •ë³´ê°€ ë‹´ê²¨ ìˆëŠ” {action_items}ë¡œë¶€í„° title, description, assignee, endDate, epicIdì˜ ì •ë³´ë¥¼ ì™„ì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
    ë°˜ë“œì‹œ ë‹¤ìŒì˜ ê³¼ì •ì„ ë”°ë¼ì„œ {action_items}ì— ì¡´ì¬í•˜ëŠ” itemì„ í•˜ë‚˜ì”© ì²˜ë¦¬í•˜ê³ , ëª¨ë“  itemì´ ì²˜ë¦¬ë˜ë„ë¡ í•˜ì„¸ìš”.
    1. {action_items}ì—ì„œ keyê°’ìœ¼ë¡œ description, assignee, endDateê°€ ì¡´ì¬í•˜ëŠ” ë‹¤ìŒ itemì„ ì„ íƒí•´ì„œ assigneeì™€ endDateê°€ nullì¸ì§€ í™•ì¸í•˜ì„¸ìš”.
    2. assingeeê°€ nullì¸ ê²½ìš° nullì„ ê°’ìœ¼ë¡œ ê·¸ëŒ€ë¡œ ë°˜í™˜í•˜ê³ , nullì´ ì•„ë‹Œ ê²½ìš° assigneeê°€ {project_members}ì— ì†í•œ êµ¬ì„±ì›ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.
    assigneeê°€ ë©¤ë²„ì˜ ì´ë¦„ì´ ì•„ë‹Œ positionì˜ ì´ë¦„ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ {project_members}ë¡œë¶€í„° ë©¤ë²„ì˜ ì´ë¦„ê³¼ position ì •ë³´ë¥¼ ëª¨ë‘ í™•ì¸í•˜ê³ , positionì´ assgineeì— ì í˜€ ìˆëŠ” ê²½ìš° êµ¬ì„±ì›ì˜ ì´ë¦„ìœ¼ë¡œ ëŒ€ì²´í•˜ì—¬ ë°˜í™˜í•˜ì„¸ìš”.
    ë©¤ë²„ì˜ ì´ë¦„ê³¼ position ì •ë³´ê°€ ëª¨ë‘ ì¼ì¹˜í•˜ì§€ ì•ŠëŠ” ê²½ìš°ì—ë§Œ assignee ê°’ìœ¼ë¡œ nullì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    3. endDateëŠ” endDateê°€ nullì¸ ê²½ìš° nullì„ ê°’ìœ¼ë¡œ ê·¸ëŒ€ë¡œ ë°˜í™˜í•˜ê³ , nullì´ ì•„ë‹Œ ê²½ìš° endDateê°€ ì˜¤ëŠ˜ ë‚ ì§œ ì´í›„ì¸ì§€ í™•ì¸í•˜ì„¸ìš”. ë§Œì•½ ì˜¤ëŠ˜ ë‚ ì§œ ì´í›„ê°€ ì•„ë‹Œ ê²½ìš° endDate ê°’ìœ¼ë¡œ nullì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    endDateëŠ” datetime í˜•ì‹ì„ ì§€ë‹Œ stringìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”.
    4. descriptionì„ 10ê¸€ì ì´ë‚´ë¡œ ìš”ì•½í•˜ì—¬ titleì„ êµ¬ì„±í•˜ì„¸ìš”.
    5. {epics}ì—ëŠ” í”„ë¡œì íŠ¸ì— ì†í•œ ëª¨ë“  epicë“¤ì˜ title, description, id ì •ë³´ê°€ ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬ë˜ì–´ ìˆìŠµë‹ˆë‹¤: "ë‚´ìš©: (description) --- id: (ObjectId)"
    epicë³„ descriptionì„ ë°”íƒ•ìœ¼ë¡œ í˜„ì¬ itemì˜ ë‚´ìš©ê³¼ ê°€ì¥ ìœ ì‚¬í•œ epicì„ {epics} ëª©ë¡ ì•ˆì—ì„œ ì„ íƒí•˜ì„¸ìš”. ì´ ë•Œ 'ìœ ì‚¬í•˜ë‹¤'ì˜ ì •ì˜ëŠ” epicì˜ descriptionê³¼ itemì˜ description ê°„ì˜ cosine similarityê°€ 0.95 ì´ìƒì„ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
    ë§Œì•½ ìœ ì‚¬í•œ epicì´ ì„ íƒë˜ì§€ ì•Šì€ ê²½ìš°ì—ëŠ” cosine similarityì˜ thresholdë¥¼ 0.95ì—ì„œ 0.90ìœ¼ë¡œ ë‚®ì¶°ì„œ ë‹¤ì‹œ ìœ ì‚¬í•œ epicì„ ì„ íƒí•˜ì„¸ìš”.
    ì´ ë•Œë„ ìœ ì‚¬í•œ epicì´ ì„ íƒë˜ì§€ ì•Šìœ¼ë©´ thresholdë¥¼ í•œ ë²ˆ ë” 0.90ì—ì„œ 0.80ìœ¼ë¡œ ì¡°ì •í•©ë‹ˆë‹¤.
    ê·¸ëŸ¼ì—ë„ ì„ íƒë˜ì§€ ì•ŠëŠ”ë‹¤ë©´ nullì„ ë°˜í™˜í•˜ì„¸ìš”.
    6. 5ë²ˆì—ì„œ ì„ íƒí•œ epicì˜ idë¥¼ epicIdë¡œ ë°˜í™˜í•˜ì„¸ìš”. ì´ë•Œ ì§ì ‘ epicIdë¥¼ ìƒì„±í•˜ëŠ” ê²Œ ì•„ë‹ˆë¼ ë°˜ë“œì‹œ {epics}ì— ì €ì¥ë˜ì–´ ìˆëŠ” id ê°’ì„ ê·¸ëŒ€ë¡œ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤. í•œ ë²ˆ ë” ê°•ì¡°í•©ë‹ˆë‹¤. ì ˆëŒ€ epicIdë¥¼ ì„ì˜ë¡œ ìƒì„±í•˜ì§€ ë§ê³  ìˆëŠ” ì •ë³´ë¥¼ ê·¸ëŒ€ë¡œ ì…ë ¥í•˜ì„¸ìš”.
    
    ê²°ê³¼ë¥¼ ë‹¤ìŒê³¼ ê°™ì€ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ ì£¼ì„¸ìš”. ë‹¤ë¥¸ í˜•ì‹ì˜ ì‘ë‹µì€ í—ˆìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë§í•˜ì§€ë§Œ ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ ì£¼ì„¸ìš”.
    {{
        "actionItems": [
            {{
                "title": "string",
                "description": "string",
                "assigneeId": "string" | null,
                "endDate": "string" | null,
                "epicId": "string"
            }},
            ...
        ]
    }}
    """)
    epic_collection = await get_epic_collection()
    epics = await epic_collection.find({"projectId": project_id}).to_list(length=None)
    epics_content = "\n".join([f"epic_description: {epic['description']} --- epic_id: ({epic['_id']})" for epic in epics])  # epicë“¤ì˜ title, description, id ì •ë³´ë¥¼ ë¬¸ìì—´ë¡œ ì •ë¦¬
    #logger.info(f"ì •ë¦¬ëœ epics_content: {epics_content}")
    
    project_members = await get_project_members(project_id)
    
    messages = action_items_to_tasks_prompt.format(
        action_items=action_items,
        project_members=project_members,
        epics=epics_content
    )
    llm = ChatOpenAI(
        model_name="gpt-4o",
        temperature=0.2,
    )
    response = await llm.ainvoke(messages)
    try:
        content = response.content
        try:
            gpt_result = extract_json_from_gpt_response(content)
        except Exception as e:
            logger.error(f"GPT util ì‚¬ìš© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
            raise Exception(f"GPT util ì‚¬ìš© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True) from e
    except Exception as e:
        logger.error(f"GPT API ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        raise Exception(f"GPT API ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True) from e
    
    response = gpt_result["actionItems"]
    logger.info(f"actionItems êµ¬ì„± ê²°ê³¼: {response}")
    
    # assignee ì´ë¦„ì„ ëŒ€ì‘ë˜ëŠ” idë¡œ ë³€ê²½
    name_to_id = {}
    user_collection = await get_user_collection()
    project_collection = await get_project_collection()
    project_data = await project_collection.find_one({"_id": project_id})   # DBRefì—ì„œ ì§ì ‘ ID ë§¤í•‘ ìƒì„±
    logger.info("ğŸ” í”„ë¡œì íŠ¸ ë©¤ë²„ name:id mapping ì‹œì‘")
    for member_ref in project_data["members"]:
        try:
            user_id = member_ref.id
            user_info = await user_collection.find_one({"_id": user_id})
            if user_info is None:
                logger.warning(f"âš ï¸ ì‚¬ìš©ì ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {user_id}")
                continue
            
            name = user_info.get("name")
            if name is None:
                logger.warning(f"âš ï¸ ì‚¬ìš©ì ì´ë¦„ì´ ì—†ìŠµë‹ˆë‹¤: {user_id}")
                continue
            
            # ObjectIdë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            name_to_id[name] = str(user_id)
            logger.info(f"âœ… ì‚¬ìš©ì ë§¤í•‘ ì„±ê³µ - ì´ë¦„: {name}, ID: {str(user_id)}")
        except Exception as e:
            logger.error(f"âŒ ì‚¬ìš©ì ì •ë³´ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
            continue
    
    assert name_to_id is not None, "name_to_id ë§¤í•‘ ì •ë³´ê°€ êµ¬ì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."    # mapping ì—¬ë¶€ ê²€ì¦
    
    for item in response:
        try:
            # ë‹´ë‹¹ìë¥¼ ì´ë¦„:id mapping
            if item["assigneeId"] is None:
                logger.info(f"ğŸ“Œ {item['description']}ì˜ ë‹´ë‹¹ìê°€ nullì…ë‹ˆë‹¤.")
                #continue
            elif item["assigneeId"] in name_to_id:
                logger.info(f"âœ… {item['title']}ì˜ ë‹´ë‹¹ìì¸ {item['assigneeId']}ê°€ ë§¤í•‘ëœ name_to_idì— ì¡´ì¬í•©ë‹ˆë‹¤.")
                item["assigneeId"] = name_to_id[item["assigneeId"]]
            else:
                logger.info(f"âš ï¸ {item['title']}ì˜ ë‹´ë‹¹ìê°€ {item['assigneeId']}ë¡œ ì¡´ì¬í•˜ì§€ë§Œ name_to_idì— ë§¤í•‘ëœ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
                item["assigneeId"] = None
        except Exception as e:
            logger.error(f"name_to_id ë§¤í•‘ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)

        # epicì´ ì˜¬ë°”ë¥´ê²Œ ì—°ê²°ë˜ì—ˆëŠ”ì§€ í™•ì¸
        try:
            if item["epicId"] is not None:
                logger.info(f"âœ… {item['title']}ì— ë§¤í•‘ëœ epicIdê°€ ì¡´ì¬í•©ë‹ˆë‹¤. epicId: {item['epicId']}")
                try:
                    selected_epic = await epic_collection.find_one({"_id": item["epicId"]})
                    logger.info(f"ğŸ” epicIdë¥¼ ì‚¬ìš©í•´ì„œ epic collectionìœ¼ë¡œë¶€í„° ì¡°íšŒëœ epic ì œëª©: {selected_epic['title']}")
                except Exception as e:
                    logger.warning(f"âš ï¸ ì•¡ì…˜ ì•„ì´í…œì— í• ë‹¹ëœ epicIdê°€ ì¡´ì¬í•˜ì§€ë§Œ ì‹¤ì œ epic collectionì—ì„œ ì¡°íšŒë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì˜¤ë¥˜ ë‚´ìš©: {str(e)}", exc_info=True)
                    item["epicId"] = None
            else:
                logger.info(f"ğŸ” {item['title']}ì— ë§¤í•‘ëœ epicì´ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            logger.error(f"epicId ë§¤í•‘ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
            
        # endDateê°€ nullì„ ë°˜í™˜í•˜ëŠ” ê²½ìš°, 'null'ì´ ì•„ë‹Œ nullì„ ì œëŒ€ë¡œ ë°˜í™˜í•˜ëŠ”ì§€ í™•ì¸
        try:
            if item["endDate"] == 'null':
                logger.warning(f"âš ï¸ {item['title']}ì˜ endDateê°€ string 'null'ë¡œ ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
                item["endDate"] = None
        except Exception as e:
            logger.error(f"endDate ë§¤í•‘ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)

    logger.info(f"ğŸ” ë‹¤ìŒì´ APIì˜ responseë¡œ ë°˜í™˜ë©ë‹ˆë‹¤: {response}")
    return response

### ============================== ë©”ì¸ routing í•¨ìˆ˜ ============================== ###
async def analyze_meeting_document(title: str, content: str, project_id: str):
    '''
    # md íŒŒì¼ì— ëŒ€í•œ ìš”ì•½ ìƒì„±
    - ê²°ê³¼ë¥¼ md íŒŒì¼ë¡œ ë°˜í™˜í•´ì•¼ í•¨
    - ì›ë³¸ì— ìˆëŠ” Heading ë ˆë²¨ì„ ìš”ì•½ë³¸ì—ì„œë„ ìœ ì§€í•´ì•¼ í•¨
    - íšŒì˜ ì œëª©ì„ ë°”íƒ•ìœ¼ë¡œ ìš”ì•½ë³¸ì´ ë™ì¼í•œ ë°©í–¥ì„±ì„ ë„ëŠ”ì§€ ì •ì„±ì ìœ¼ë¡œ í‰ê°€
    
    '''   
    summary = await create_summary(title, content, project_id)
    logger.info(f"âœ… ìƒì„±ëœ íšŒì˜ ìš”ì•½: {summary}")
    
    '''
    # ì•¡ì…˜ ì•„ì´í…œ ìƒì„±
    - ìš”ì•½í•œ ê²°ê³¼ì— ì•¡ì…˜ ì•„ì´í…œì„ í¬í•¨í•´ì„œ ë¶„ì„í• ì§€ ì•„ë‹ˆë©´ ì›ë³¸ì—ì„œë¶€í„° ì‹œì‘í• ì§€ ê²°ì •í•´ì•¼ í•¨ (ì¼ë‹¨ í›„ìë¡œ ì§„í–‰)
    - ì•¡ì…˜ ì•„ì´í…œì˜ ë‚´ìš©ìœ¼ë¡œ (task, assingee, endDate) ìŒì˜ ì§‘í•©ì„ ë°˜í™˜ë°›ì•„ì•¼ í•¨
    - ë°˜í™˜ëœ action_itemsë¥¼ convert_action_items_to_tasks í•¨ìˆ˜ì— ì¸ìˆ˜ë¡œ ì „ë‹¬
    '''
    action_items = await create_action_items_gpt(content)
    logger.info(f"âœ… ìƒì„±ëœ ì•¡ì…˜ ì•„ì´í…œ: {action_items}")
    
    '''
    # action_itemsë¥¼ taskë¡œ ë³€í™˜
    - action itemsì—ëŠ” task ê¸°ì¤€ì—ì„œ description, assignee, endDate ì •ë³´ê°€ ë‹´ê²¨ ìˆìŒ
    - ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ title, epicIdë¥¼ ë¶€ì—¬í•˜ê³  assingee ì´ë¦„ì„ ëŒ€ì‘ë˜ëŠ” idë¡œ ë³€ê²½í•´ì•¼ í•¨
    - ë‹¨, assignee, endDateê°€ nullì¼ ìˆ˜ ìˆëŠ”ë° ì´ ê²½ìš°ì—ëŠ” ì¼ë‹¨ nullë¡œ ëª¨ë‘ ë°˜í™˜ -> ì´í›„ì— ì¶”ê°€ ì²˜ë¦¬ í•„ìš”
    '''
    actionItems = await convert_action_items_to_tasks(action_items, project_id)
    logger.info(f"âœ… taskë¡œ ë³€í™˜ëœ ì•¡ì…˜ ì•„ì´í…œ: {actionItems}")
    
    response = {
        "summary": summary,
        "actionItems": actionItems,
    }
    logger.info(f"êµ¬ì„±ëœ response: {response}")
    return response


### ============================== í…ŒìŠ¤íŠ¸ ì½”ë“œ ============================== ###
async def test_meeintg_analysis():
    with open('meeting_sample.md', 'r', encoding='utf-8') as f:
        content = f.read()
    
    # í…ŒìŠ¤íŠ¸ìš© project_id ì„¤ì •
    project_id = "b5728b16-6610-4762-b178-bb71f56a6616"
    
    title = "ê¼¼ê¼¼í•œ íšŒì˜ë¡"
    summary = await create_summary(title, content, project_id)
    print(f"ìƒì„±ëœ íšŒì˜ ìš”ì•½: {summary}")
    
    # íšŒì˜ ìš”ì•½ ìƒì„± í…ŒìŠ¤íŠ¸
    # load_dotenv()
    # print("\n=== íšŒì˜ ìš”ì•½ ìƒì„± í…ŒìŠ¤íŠ¸ - ê¼¼ê¼¼í•œ íšŒì˜ë¡ ë²„ì „ ===")
    # title = "ê¼¼ê¼¼í•œ íšŒì˜ë¡"
    # print("\n ì›ë³¸: \n")
    # with open('meeting_sample_strict.md', 'r', encoding='utf-8') as f:
    #     content = f.read()
    # print(content)
    # summary = await create_summary(title, content, project_id)
    # print(f"ìƒì„±ëœ íšŒì˜ ìš”ì•½: {summary}")
    
    # # ì•¡ì…˜ ì•„ì´í…œ ìƒì„± í…ŒìŠ¤íŠ¸
    # print("=== ì•¡ì…˜ ì•„ì´í…œ ìƒì„± í…ŒìŠ¤íŠ¸ - ê¼¼ê¼¼í•œ íšŒì˜ë¡ ë²„ì „ ===")
    # action_items = await create_action_items_gpt(content)
    # print(f"ìƒì„±ëœ ì•¡ì…˜ ì•„ì´í…œ: {action_items}")
    
    
    # print("\n=== íšŒì˜ ìš”ì•½ ìƒì„± í…ŒìŠ¤íŠ¸ - ëŠìŠ¨í•œ íšŒì˜ë¡ ===")
    # title = "ëŠìŠ¨í•œ íšŒì˜ë¡"
    # print("\n ì›ë³¸: \n")
    # with open('meeting_sample_rough.md', 'r', encoding='utf-8') as f:
    #     content = f.read()
    # print(content)
    # summary = await create_summary(title, content, project_id)
    # print(f"ìƒì„±ëœ íšŒì˜ ìš”ì•½: {summary}")
    
    # # ì•¡ì…˜ ì•„ì´í…œ ìƒì„± í…ŒìŠ¤íŠ¸
    # print("=== ì•¡ì…˜ ì•„ì´í…œ ìƒì„± í…ŒìŠ¤íŠ¸ - ëŠìŠ¨í•œ íšŒì˜ë¡ ë²„ì „ ===")
    # action_items = await create_action_items_gpt(content)
    # print(f"ìƒì„±ëœ ì•¡ì…˜ ì•„ì´í…œ: {action_items}")


if __name__ == "__main__":
    #print(model_for_ner.config.id2label)
    import asyncio
    asyncio.run(test_meeintg_analysis())